{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1966e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb9bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4654700",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 'So threatening had become the general aspect of affairs, that the king thought it prudent to send his son' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dfface9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2396, 11123, 550, 1716, 262, 2276, 4843, 286, 9674, 11, 326, 262, 5822, 1807, 340, 34998, 284, 3758, 465, 3367]\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer.encode(raw)\n",
    "print(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc980ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So threatening had become the general aspect of affairs, that the king thought it prudent to send his son\n"
     ]
    }
   ],
   "source": [
    "ret = tokenizer.decode(enc)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46c8733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0305,  3.3796, -2.5016, -1.2036,  0.2799,  2.1263,  0.1639,  0.2492],\n",
      "        [ 0.1527, -0.9483, -2.0567, -1.0204, -1.3837, -0.6000,  0.3184,  1.3188],\n",
      "        [-0.0505,  0.4629,  0.0268,  1.6601, -0.7094,  0.4188,  0.8855,  0.3651],\n",
      "        [ 1.6156,  0.2851, -0.6711, -0.3790,  0.7342, -0.9215,  0.5173,  0.1448]],\n",
      "       requires_grad=True)\n",
      "tensor([[-0.0305,  3.3796, -2.5016, -1.2036,  0.2799,  2.1263,  0.1639,  0.2492],\n",
      "        [ 0.1527, -0.9483, -2.0567, -1.0204, -1.3837, -0.6000,  0.3184,  1.3188],\n",
      "        [-0.0505,  0.4629,  0.0268,  1.6601, -0.7094,  0.4188,  0.8855,  0.3651],\n",
      "        [ 1.6156,  0.2851, -0.6711, -0.3790,  0.7342, -0.9215,  0.5173,  0.1448]])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 4\n",
    "output_dimension = 8\n",
    "inputs = torch.nn.Embedding(vocab_size, output_dimension)\n",
    "print(inputs.weight)\n",
    "\n",
    "inputs = inputs.weight.data\n",
    "print(inputs) # get the same answer without the 'requires_grad+True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d52281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0635544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.030461864545941353, 3.379633665084839, -2.501620292663574, -1.2035605907440186, 0.27994439005851746, 2.1263039112091064, 0.1639443337917328, 0.2492324411869049]\n",
      "[0.15265977382659912, -0.9482561349868774, -2.0567238330841064, -1.020434856414795, -1.383724331855774, -0.5999849438667297, 0.3184005320072174, 1.3187685012817383]\n",
      "[-0.050488781183958054, 0.462890625, 0.02684025652706623, 1.660145878791809, -0.7093648314476013, 0.41878703236579895, 0.8855202794075012, 0.36512529850006104]\n",
      "[1.6156370639801025, 0.28505197167396545, -0.6710654497146606, -0.37897810339927673, 0.7341901659965515, -0.9214617609977722, 0.5172808766365051, 0.14476490020751953]\n"
     ]
    }
   ],
   "source": [
    "for row in inputs:\n",
    "    print(row.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0fe3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([1.1, 2.3])\n",
    "y = torch.Tensor([3.4, -2.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c9b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0900)\n",
      "-1.0899999999999999\n"
     ]
    }
   ],
   "source": [
    "print(torch.dot(x, y))\n",
    "\n",
    "print(1.1 * 3.4 + 2.3 * (-2.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8626e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0505,  0.4629,  0.0268,  1.6601, -0.7094,  0.4188,  0.8855,  0.3651])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[2]\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5052374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4288)\n",
      "tensor(-0.7022)\n",
      "tensor(4.5697)\n",
      "tensor(-0.9926)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inputs)):\n",
    "    print(torch.dot(query, inputs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4288, -0.7022,  4.5697, -0.9926])\n"
     ]
    }
   ],
   "source": [
    "# initiate a list of tensors with length of rows in inputs that has zeros as values and stores scores after loop\n",
    "att_scores2 = torch.zeros(len(inputs))\n",
    "for i in range(len(inputs)):\n",
    "    att_scores2[i] = torch.dot(query, inputs[i])\n",
    "\n",
    "print(att_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f68bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0155, 0.0050, 0.9757, 0.0037])\n"
     ]
    }
   ],
   "source": [
    "# scores + normaliazation = weights\n",
    "att_weights2 = torch.softmax(att_scores2, dim = 0) # torch.exp(x)/ torch.exp(x).sum()\n",
    "print(att_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24d10460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffd44d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0429,  0.5004, -0.0255,  1.5946, -0.6920,  0.4352,  0.8701,  0.3673])\n"
     ]
    }
   ],
   "source": [
    "context_vector2 = torch.zeros(query.shape)\n",
    "for i in range(len(att_weights2)):\n",
    "    context_vector2 += att_weights2[i] * inputs[i]\n",
    "print(context_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1931d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0305,  3.3796, -2.5016, -1.2036,  0.2799,  2.1263,  0.1639,  0.2492],\n",
      "        [ 0.1527, -0.9483, -2.0567, -1.0204, -1.3837, -0.6000,  0.3184,  1.3188],\n",
      "        [-0.0505,  0.4629,  0.0268,  1.6601, -0.7094,  0.4188,  0.8855,  0.3651],\n",
      "        [ 1.6156,  0.2851, -0.6711, -0.3790,  0.7342, -0.9215,  0.5173,  0.1448]])\n",
      "tensor([[-0.0305,  0.1527, -0.0505,  1.6156],\n",
      "        [ 3.3796, -0.9483,  0.4629,  0.2851],\n",
      "        [-2.5016, -2.0567,  0.0268, -0.6711],\n",
      "        [-1.2036, -1.0204,  1.6601, -0.3790],\n",
      "        [ 0.2799, -1.3837, -0.7094,  0.7342],\n",
      "        [ 2.1263, -0.6000,  0.4188, -0.9215],\n",
      "        [ 0.1639,  0.3184,  0.8855,  0.5173],\n",
      "        [ 0.2492,  1.3188,  0.3651,  0.1448]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(inputs.T) # flips axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252805f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[23.8180,  1.8817,  0.4288,  1.4161],\n",
      "        [ 1.8817, 10.3091, -0.7022,  1.6358],\n",
      "        [ 0.4288, -0.7022,  4.5697, -0.9926],\n",
      "        [ 1.4161,  1.6358, -0.9926,  4.9622]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication of the inputs to get att scores of the whole thing\n",
    "attention_scores = inputs @ inputs.T\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b987295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 2.9727e-10, 6.9529e-11, 1.8663e-10],\n",
      "        [2.1869e-04, 9.9959e-01, 1.6508e-05, 1.7103e-04],\n",
      "        [1.5522e-02, 5.0096e-03, 9.7572e-01, 3.7469e-03],\n",
      "        [2.7019e-02, 3.3657e-02, 2.4299e-03, 9.3689e-01]])\n"
     ]
    }
   ],
   "source": [
    "attention_weights = torch.softmax( attention_scores, dim = -1 )\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fad30954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.0000)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(attention_weights[0].sum())\n",
    "print(attention_weights[1].sum())\n",
    "print(attention_weights[2].sum())\n",
    "print(attention_weights[3].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fdc414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0305,  3.3796, -2.5016, -1.2036,  0.2799,  2.1263,  0.1639,  0.2492],\n",
      "        [ 0.1529, -0.9471, -2.0565, -1.0203, -1.3830, -0.5994,  0.3184,  1.3183],\n",
      "        [-0.0429,  0.5004, -0.0255,  1.5946, -0.6920,  0.4352,  0.8701,  0.3673],\n",
      "        [ 1.5179,  0.3276, -0.7655, -0.4179,  0.6471, -0.8250,  0.5019,  0.1876]])\n"
     ]
    }
   ],
   "source": [
    "# Again, matrix multiplication of all weights with inputs to get the context vectors (automatically summed into the list)\n",
    "context_vectors = attention_weights @ inputs\n",
    "print(context_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
