{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1966e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beb9bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4654700",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 'So threatening had become the general aspect of affairs, that the king thought it prudent to send his son' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dfface9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2396, 11123, 550, 1716, 262, 2276, 4843, 286, 9674, 11, 326, 262, 5822, 1807, 340, 34998, 284, 3758, 465, 3367]\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer.encode(raw)\n",
    "print(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc980ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So threatening had become the general aspect of affairs, that the king thought it prudent to send his son\n"
     ]
    }
   ],
   "source": [
    "ret = tokenizer.decode(enc)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a46c8733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.2333, -1.1896, -0.6725,  0.3895,  0.1615,  0.3366,  0.1482, -1.4482],\n",
      "        [-1.9821,  2.6993, -1.2479, -0.3451, -1.8017, -0.0958,  0.2081, -0.1727],\n",
      "        [ 0.1061,  1.3612,  0.2706, -0.7686, -0.2944,  1.5069,  0.5106,  0.5482],\n",
      "        [-0.1095,  1.6537,  0.5615,  0.6544, -1.0156, -0.9757, -1.6549, -1.2158]],\n",
      "       requires_grad=True)\n",
      "tensor([[-1.2333, -1.1896, -0.6725,  0.3895,  0.1615,  0.3366,  0.1482, -1.4482],\n",
      "        [-1.9821,  2.6993, -1.2479, -0.3451, -1.8017, -0.0958,  0.2081, -0.1727],\n",
      "        [ 0.1061,  1.3612,  0.2706, -0.7686, -0.2944,  1.5069,  0.5106,  0.5482],\n",
      "        [-0.1095,  1.6537,  0.5615,  0.6544, -1.0156, -0.9757, -1.6549, -1.2158]])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 4\n",
    "output_dimension = 8\n",
    "inputs = torch.nn.Embedding(vocab_size, output_dimension)\n",
    "print(inputs.weight)\n",
    "\n",
    "inputs = inputs.weight.data\n",
    "print(inputs) # get the same answer without the 'requires_grad+True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5d52281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0635544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.2333179712295532, -1.1896461248397827, -0.6725375652313232, 0.3895379304885864, 0.16151940822601318, 0.3366181552410126, 0.14821209013462067, -1.4482097625732422]\n",
      "[-1.9821252822875977, 2.6993346214294434, -1.2479064464569092, -0.345114141702652, -1.8016605377197266, -0.095818892121315, 0.20806346833705902, -0.17266066372394562]\n",
      "[0.10607588291168213, 1.3611797094345093, 0.2705560624599457, -0.7686013579368591, -0.29441431164741516, 1.5068678855895996, 0.5106224417686462, 0.5482245087623596]\n",
      "[-0.10945736616849899, 1.653702735900879, 0.5614665746688843, 0.6544092893600464, -1.0155706405639648, -0.9756858944892883, -1.6548634767532349, -1.2157646417617798]\n"
     ]
    }
   ],
   "source": [
    "for row in inputs:\n",
    "    print(row.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0fe3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([1.1, 2.3])\n",
    "y = torch.Tensor([3.4, -2.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61c9b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0900)\n",
      "-1.0899999999999999\n"
     ]
    }
   ],
   "source": [
    "print(torch.dot(x, y))\n",
    "\n",
    "print(1.1 * 3.4 + 2.3 * (-2.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8626e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1061,  1.3612,  0.2706, -0.7686, -0.2944,  1.5069,  0.5106,  0.5482])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[2]\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5052374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.4901)\n",
      "tensor(3.7893)\n",
      "tensor(5.4466)\n",
      "tensor(-0.7944)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inputs)):\n",
    "    print(torch.dot(query, inputs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b649c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.4901,  3.7893,  5.4466, -0.7944])\n"
     ]
    }
   ],
   "source": [
    "att_scores2 = torch.zeros(len(inputs))\n",
    "for i in range(len(inputs)):\n",
    "    att_scores2[i] = torch.dot(query, inputs[i])\n",
    "\n",
    "print(att_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73f68bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9958e-04, 1.5981e-01, 8.3826e-01, 1.6327e-03])\n"
     ]
    }
   ],
   "source": [
    "att_weights2 = torch.softmax(att_scores2, dim = 0) # torch.exp(x)/ torch.exp(x).sum()\n",
    "print(att_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24d10460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffd44d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2284,  1.5747,  0.0281, -0.6983, -0.5363,  1.2463,  0.4586,  0.4295])\n"
     ]
    }
   ],
   "source": [
    "context_vector2 = torch.zeros(query.shape)\n",
    "for i in range(len(att_weights2)):\n",
    "    context_vector2 += att_weights2[i] * inputs[i]\n",
    "print(context_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1931d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2333, -1.1896, -0.6725,  0.3895,  0.1615,  0.3366,  0.1482, -1.4482],\n",
      "        [-1.9821,  2.6993, -1.2479, -0.3451, -1.8017, -0.0958,  0.2081, -0.1727],\n",
      "        [ 0.1061,  1.3612,  0.2706, -0.7686, -0.2944,  1.5069,  0.5106,  0.5482],\n",
      "        [-0.1095,  1.6537,  0.5615,  0.6544, -1.0156, -0.9757, -1.6549, -1.2158]])\n",
      "tensor([[-1.2333, -1.9821,  0.1061, -0.1095],\n",
      "        [-1.1896,  2.6993,  1.3612,  1.6537],\n",
      "        [-0.6725, -1.2479,  0.2706,  0.5615],\n",
      "        [ 0.3895, -0.3451, -0.7686,  0.6544],\n",
      "        [ 0.1615, -1.8017, -0.2944, -1.0156],\n",
      "        [ 0.3366, -0.0958,  1.5069, -0.9757],\n",
      "        [ 0.1482,  0.2081,  0.5106, -1.6549],\n",
      "        [-1.4482, -0.1727,  0.5482, -1.2158]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(inputs.T) # flips axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "252805f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.7991, -0.1042, -2.4901, -0.9321],\n",
      "        [-0.1042, 16.2199,  3.7893,  5.5432],\n",
      "        [-2.4901,  3.7893,  5.4466, -0.7944],\n",
      "        [-0.9321,  5.5432, -0.7944,  9.6902]])\n"
     ]
    }
   ],
   "source": [
    "attention_scores = inputs @ inputs.T\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b987295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9584e-01, 2.7192e-03, 2.5019e-04, 1.1882e-03],\n",
      "        [8.1383e-08, 9.9997e-01, 3.9944e-06, 2.3075e-05],\n",
      "        [2.9958e-04, 1.5981e-01, 8.3826e-01, 1.6327e-03],\n",
      "        [2.3986e-05, 1.5564e-02, 2.7525e-05, 9.8438e-01]])\n"
     ]
    }
   ],
   "source": [
    "attention_weights = torch.softmax( attention_scores, dim = -1 )\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fad30954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "print(attention_weights[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40fdc414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2337, -1.1751, -0.6724,  0.3876,  0.1547,  0.3342,  0.1463, -1.4440],\n",
      "        [-1.9821,  2.6993, -1.2479, -0.3451, -1.8016, -0.0958,  0.2080, -0.1727],\n",
      "        [-0.2284,  1.5747,  0.0281, -0.6983, -0.5363,  1.2463,  0.4586,  0.4295],\n",
      "        [-0.1386,  1.6699,  0.5333,  0.6388, -1.0278, -0.9619, -1.6258, -1.1995]])\n"
     ]
    }
   ],
   "source": [
    "context_vectors = attention_weights @ inputs\n",
    "print(context_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
