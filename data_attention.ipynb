{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642f47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b07ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e148416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ancient Egypt (Rawlinson)\\nby George Rawlinson\\nThe '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"tokenization_example_story.txt\", 'r') as f:\n",
    "    raw = f.read()\n",
    "\n",
    "raw[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44974, 6365, 357, 27369, 75, 7899, 8, 198, 1525, 4502, 16089, 75, 7899, 198, 464, 20876, 12, 42912, 438, 28348]\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode(raw)\n",
    "print(enc_text[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c480976",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25cfe25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98e909ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[44974,  6365,   357, 27369],\n",
      "        [   75,  7899,     8,   198],\n",
      "        [ 1525,  4502, 16089,    75],\n",
      "        [ 7899,   198,   464, 20876],\n",
      "        [   12, 42912,   438, 28348],\n",
      "        [  316,   368,   290, 22912],\n",
      "        [  198,  9693,  1797,  7801],\n",
      "        [   42,  5357, 33700,   360]])\n",
      "\n",
      "Targets:\n",
      " tensor([[ 6365,   357, 27369,    75],\n",
      "        [ 7899,     8,   198,  1525],\n",
      "        [ 4502, 16089,    75,  7899],\n",
      "        [  198,   464, 20876,    12],\n",
      "        [42912,   438, 28348,   316],\n",
      "        [  368,   290, 22912,   198],\n",
      "        [ 9693,  1797,  7801,    42],\n",
      "        [ 5357, 33700,   360,    56]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw, batch_size = 8, \n",
    "                                  max_length = 4,\n",
    "                                  stride = 4, \n",
    "                                  shuffle = False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7a4b4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[44974,  6365,   357, 27369,    75,  7899,     8,   198],\n",
      "        [  357, 27369,    75,  7899,     8,   198,  1525,  4502],\n",
      "        [   75,  7899,     8,   198,  1525,  4502, 16089,    75],\n",
      "        [    8,   198,  1525,  4502, 16089,    75,  7899,   198]])\n",
      "\n",
      "Targets:\n",
      " tensor([[ 6365,   357, 27369,    75,  7899,     8,   198,  1525],\n",
      "        [27369,    75,  7899,     8,   198,  1525,  4502, 16089],\n",
      "        [ 7899,     8,   198,  1525,  4502, 16089,    75,  7899],\n",
      "        [  198,  1525,  4502, 16089,    75,  7899,   198,   464]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw, batch_size = 4, \n",
    "                                  max_length = 8,\n",
    "                                  stride = 2, \n",
    "                                  shuffle = False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9600824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Inputs---\n",
      "Ancient Egypt (Rawlinson)\n",
      "\n",
      " (Rawlinson)\n",
      "by George\n",
      "linson)\n",
      "by George Rawl\n",
      ")\n",
      "by George Rawlinson\n",
      "\n",
      "---Targets---\n",
      " Egypt (Rawlinson)\n",
      "by\n",
      "Rawlinson)\n",
      "by George Raw\n",
      "inson)\n",
      "by George Rawlinson\n",
      "\n",
      "by George Rawlinson\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "print(\"---Inputs---\")\n",
    "for row in inputs:\n",
    "    print(tokenizer.decode(row.tolist()))\n",
    "\n",
    "print(\"---Targets---\")\n",
    "for row in targets:\n",
    "    print(tokenizer.decode(row.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b926eb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3515,  0.5515,  0.6998, -1.3848],\n",
      "        [-0.7287,  2.7778,  1.2920,  0.7715],\n",
      "        [ 0.7276,  0.0487, -0.1974, -1.3474],\n",
      "        [ 2.0222,  0.5559, -0.2078, -2.8626],\n",
      "        [ 0.2084, -0.6497, -2.3198, -0.8974],\n",
      "        [-0.1778, -0.5824, -0.8684, -0.5789],\n",
      "        [-0.0176,  0.3617,  0.0533, -2.4587],\n",
      "        [-0.4878, -0.0351,  0.0423, -0.0046]], requires_grad=True)\n",
      "tensor([[-0.3515,  0.5515,  0.6998, -1.3848],\n",
      "        [-0.7287,  2.7778,  1.2920,  0.7715],\n",
      "        [ 0.7276,  0.0487, -0.1974, -1.3474],\n",
      "        [ 2.0222,  0.5559, -0.2078, -2.8626],\n",
      "        [ 0.2084, -0.6497, -2.3198, -0.8974],\n",
      "        [-0.1778, -0.5824, -0.8684, -0.5789],\n",
      "        [-0.0176,  0.3617,  0.0533, -2.4587],\n",
      "        [-0.4878, -0.0351,  0.0423, -0.0046]])\n"
     ]
    }
   ],
   "source": [
    "# There is a vocabulary of size 8 ( 8 words, or IDs), whereas each token will be represented by a vector of length 4.\n",
    "# So the Embedding layer creates an 8 Ã— 4 matrix- each row is initialized with random values.\n",
    "# It's necessary becasue if we just used raw IDs, the model would treat them as meaningless numbers with no relationship between them, unlike the embedding layer that teaches the model useful representations while training.\n",
    "\n",
    "vocab_size = 8\n",
    "output_dimension = 4\n",
    "inputs = torch.nn.Embedding(vocab_size, output_dimension)\n",
    "print(inputs.weight)\n",
    "\n",
    "inputs = inputs.weight.data\n",
    "print(inputs) # get the same answer without the 'requires_grad+True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15c60525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7276,  0.0487, -0.1974, -1.3474])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[2]\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a65054dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4988)\n",
      "tensor(-1.6893)\n",
      "tensor(2.3862)\n",
      "tensor(5.3965)\n",
      "tensor(1.7871)\n",
      "tensor(0.7936)\n",
      "tensor(3.3070)\n",
      "tensor(-0.3588)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(inputs)):\n",
    "    print(torch.dot(query, inputs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e61627bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4988, -1.6893,  2.3862,  5.3965,  1.7871,  0.7936,  3.3070, -0.3588])\n"
     ]
    }
   ],
   "source": [
    "att_scores = torch.zeros(len(inputs))\n",
    "for i in range(len(inputs)):\n",
    "    att_scores[i] = torch.dot(query, inputs[i])\n",
    "\n",
    "print(att_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62ccd93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6435e-02, 6.7792e-04, 3.9918e-02, 8.1011e-01, 2.1928e-02, 8.1193e-03,\n",
      "        1.0025e-01, 2.5646e-03]) \n",
      " tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "att_weights = torch.softmax(att_scores, dim = 0) # torch.exp(x)/ torch.exp(x).sum()\n",
    "print(att_weights, '\\n', att_weights.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8393ea5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.6611,  0.4804, -0.2163, -2.6659])\n"
     ]
    }
   ],
   "source": [
    "context_vector = torch.zeros(query.shape)\n",
    "for i in range(len(att_weights)):\n",
    "    context_vector += att_weights[i] * inputs[i]\n",
    "print(context_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
